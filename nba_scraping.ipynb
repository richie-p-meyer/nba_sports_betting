{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eed6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "SEASONS = list(range(2016,2024))\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "STANDINGS_DIR = os.path.join(DATA_DIR, \"standings\")\n",
    "SCORES_DIR = os.path.join(DATA_DIR, \"scores\")\n",
    "TEMP_DIR = os.path.join(DATA_DIR, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726dd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time\n",
    "# Make sure to install playwright browsers by running playwright install on the command line or !playwright install from Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f041f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_html(url, selector, sleep=5, retries=3):\n",
    "    html = None\n",
    "    for i in range(1, retries+1):\n",
    "        time.sleep(sleep * i)\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.firefox.launch()\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                print(await page.title())\n",
    "                html = await page.inner_html(selector)\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"Timeout error on {url}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_season(season):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    html = await get_html(url, \"#content .filter\")\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
    "    \n",
    "    for url in standings_pages:\n",
    "        save_path = os.path.join(STANDINGS_DIR, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        \n",
    "        html = await get_html(url, \"#all_schedule\")\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "await scrape_season(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23301710",
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_files = os.listdir(STANDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_game(standings_file):\n",
    "    with open(standings_file, 'r') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    hrefs = [l.get('href') for l in links]\n",
    "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in hrefs if l and \"boxscore\" in l and '.html' in l]\n",
    "\n",
    "    for url in box_scores:\n",
    "        save_path = os.path.join(TEMP_DIR, url.split(\"/\")[-1])\n",
    "        check_path_1 = os.path.join(SCORES_DIR, url.split(\"/\")[-1])\n",
    "        check_path_2 = os.path.join(TEMP_DIR, url.split(\"/\")[-1])\n",
    "        if os.path.exists(check_path_1) or os.path.exists(check_path_2):\n",
    "            continue\n",
    "\n",
    "        html = await get_html(url, \"#content\")\n",
    "        if not html:\n",
    "            continue\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "SEASONS = range(2022,2024)\n",
    "for season in SEASONS:\n",
    "    files = [s for s in standings_files if str(season) in s]\n",
    "    \n",
    "    for f in files:\n",
    "        filepath = os.path.join(STANDINGS_DIR, f)\n",
    "        \n",
    "        await scrape_game(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [s for s in standings_files if str(season) in s]\n",
    "for f in files:\n",
    "    filepath = os.path.join(STANDINGS_DIR, f)\n",
    "        \n",
    "    await scrape_game(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87338297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "SCORE_DIR = \"data/scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfd9f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_scores = os.listdir(SCORE_DIR)\n",
    "box_scores = [os.path.join(SCORE_DIR, f) for f in box_scores if f.endswith(\".html\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a384c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html(box_score):\n",
    "    with open(box_score) as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    [s.decompose() for s in soup.select(\"tr.over_header\")]\n",
    "    [s.decompose() for s in soup.select(\"tr.thead\")]\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44138114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season_info(soup):\n",
    "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all('a')]\n",
    "    season = os.path.basename(hrefs[1]).split(\"_\")[0]\n",
    "    return season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3141206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line_score(soup):\n",
    "    line_score = pd.read_html(str(soup), attrs = {'id': 'line_score'})[0]\n",
    "    cols = list(line_score.columns)\n",
    "    cols[0] = \"team\"\n",
    "    cols[-1] = \"total\"\n",
    "    line_score.columns = cols\n",
    "    \n",
    "    line_score = line_score[[\"team\", \"total\"]]\n",
    "    \n",
    "    return line_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f502567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line_score_test(soup):\n",
    "    teams = soup.select('.scorebox')[0]\n",
    "    hrefs = [t[\"href\"] for t in teams.find_all('a')]\n",
    "    team = [t for t in hrefs if '/teams' in t]\n",
    "    first_team = team[0].split('/')[2]\n",
    "    second_team = team[1].split('/')[2]\n",
    "    scores = soup.find_all('div',{'class':'scores'})\n",
    "    first_score = int(scores[0].text)\n",
    "    second_score =int(scores[1].text)\n",
    "    return pd.DataFrame({'team':[first_team,second_team],'total':[first_score,second_score]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fc4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stats(soup, team, stat):\n",
    "    df = pd.read_html(str(soup), attrs = {'id': f'box-{team}-game-{stat}'}, index_col=0)[0]\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b538c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = []\n",
    "base_cols = None\n",
    "for box_score in box_scores:\n",
    "    soup = parse_html(box_score)\n",
    "\n",
    "    line_score = read_line_score_test(soup)\n",
    "    teams = list(line_score[\"team\"])\n",
    "\n",
    "    summaries = []\n",
    "    for team in teams:\n",
    "        basic = read_stats(soup, team, \"basic\")\n",
    "        advanced = read_stats(soup, team, \"advanced\")\n",
    "\n",
    "        totals = pd.concat([basic.iloc[-1,:], advanced.iloc[-1,:]])\n",
    "        totals.index = totals.index.str.lower()\n",
    "\n",
    "        maxes = pd.concat([basic.iloc[:-1].max(), advanced.iloc[:-1].max()])\n",
    "        maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "        summary = pd.concat([totals, maxes])\n",
    "        \n",
    "        if base_cols is None:\n",
    "            base_cols = list(summary.index.drop_duplicates(keep=\"first\"))\n",
    "            base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "        \n",
    "        summary = summary[base_cols]\n",
    "        \n",
    "        summaries.append(summary)\n",
    "    summary = pd.concat(summaries, axis=1).T\n",
    "\n",
    "    game = pd.concat([summary, line_score], axis=1)\n",
    "\n",
    "    game[\"home\"] = [0,1]\n",
    "\n",
    "    game_opp = game.iloc[::-1].reset_index()\n",
    "    game_opp.columns += \"_opp\"\n",
    "\n",
    "    full_game = pd.concat([game, game_opp], axis=1)\n",
    "    full_game[\"season\"] = read_season_info(soup)\n",
    "    \n",
    "    full_game[\"date\"] = os.path.basename(box_score)[:8]\n",
    "    full_game[\"date\"] = pd.to_datetime(full_game[\"date\"], format=\"%Y%m%d\")\n",
    "    \n",
    "    full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "    games.append(full_game)\n",
    "    \n",
    "    if len(games) % 100 == 0:\n",
    "        print(f\"{len(games)} / {len(box_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df = pd.concat(games, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "games_df.to_csv(\"nba_games_updated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7031e9d",
   "metadata": {},
   "source": [
    "# Run following cells to update data, change month as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "166dceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "SEASONS = list(range(2016,2024))\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "STANDINGS_DIR = os.path.join(DATA_DIR, \"standings\")\n",
    "SCORES_DIR = os.path.join(DATA_DIR, \"scores\")\n",
    "TEMP_DIR = os.path.join(DATA_DIR, \"temp\")\n",
    "standings_files = os.listdir(STANDINGS_DIR)\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time\n",
    "# Make sure to install playwright browsers by running playwright install on the command line or !playwright install from Jupyter\n",
    "\n",
    "async def get_html(url, selector, sleep=5, retries=3):\n",
    "    html = None\n",
    "    for i in range(1, retries+1):\n",
    "        time.sleep(sleep * i)\n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                browser = await p.firefox.launch()\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                print(await page.title())\n",
    "                html = await page.inner_html(selector)\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"Timeout error on {url}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return html\n",
    "\n",
    "async def scrape_season(season):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    html = await get_html(url, \"#content .filter\")\n",
    "    \n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    standings_pages = [f\"https://www.basketball-reference.com{l['href']}\" for l in links]\n",
    "    \n",
    "    for url in standings_pages:\n",
    "        save_path = os.path.join(STANDINGS_DIR, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "        \n",
    "        html = await get_html(url, \"#all_schedule\")\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "            \n",
    "async def scrape_game(standings_file):\n",
    "    with open(standings_file, 'r') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    hrefs = [l.get('href') for l in links]\n",
    "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in hrefs if l and \"boxscore\" in l and '.html' in l]\n",
    "\n",
    "    for url in box_scores:\n",
    "        save_path = os.path.join(TEMP_DIR, url.split(\"/\")[-1])\n",
    "        check_path_1 = os.path.join(SCORES_DIR, url.split(\"/\")[-1])\n",
    "        check_path_2 = os.path.join(TEMP_DIR, url.split(\"/\")[-1])\n",
    "        if os.path.exists(check_path_1) or os.path.exists(check_path_2):\n",
    "            continue\n",
    "\n",
    "        html = await get_html(url, \"#content\")\n",
    "        if not html:\n",
    "            continue\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "            \n",
    "def parse_html(box_score):\n",
    "    with open(box_score) as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    [s.decompose() for s in soup.select(\"tr.over_header\")]\n",
    "    [s.decompose() for s in soup.select(\"tr.thead\")]\n",
    "    return soup\n",
    "\n",
    "def read_season_info(soup):\n",
    "    nav = soup.select(\"#bottom_nav_container\")[0]\n",
    "    hrefs = [a[\"href\"] for a in nav.find_all('a')]\n",
    "    season = os.path.basename(hrefs[1]).split(\"_\")[0]\n",
    "    return season\n",
    "\n",
    "def read_line_score(soup):\n",
    "    line_score = pd.read_html(str(soup), attrs = {'id': 'line_score'})[0]\n",
    "    cols = list(line_score.columns)\n",
    "    cols[0] = \"team\"\n",
    "    cols[-1] = \"total\"\n",
    "    line_score.columns = cols\n",
    "    \n",
    "    line_score = line_score[[\"team\", \"total\"]]\n",
    "    \n",
    "    return line_score\n",
    "\n",
    "def read_stats(soup, team, stat):\n",
    "    df = pd.read_html(str(soup), attrs = {'id': f'box-{team}-game-{stat}'}, index_col=0)[0]\n",
    "    df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "def read_line_score_test(soup):\n",
    "    teams = soup.select('.scorebox')[0]\n",
    "    hrefs = [t[\"href\"] for t in teams.find_all('a')]\n",
    "    team = [t for t in hrefs if '/teams' in t]\n",
    "    first_team = team[0].split('/')[2]\n",
    "    second_team = team[1].split('/')[2]\n",
    "    scores = soup.find_all('div',{'class':'scores'})\n",
    "    first_score = int(scores[0].text)\n",
    "    second_score =int(scores[1].text)\n",
    "    return pd.DataFrame({'team':[first_team,second_team],'total':[first_score,second_score]})\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabee439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-23 NBA Schedule | Basketball-Reference.com\n",
      "Timeout error on https://www.basketball-reference.com/leagues/NBA_2023_games-january.html\n",
      "2022-23 NBA Schedule | Basketball-Reference.com\n"
     ]
    }
   ],
   "source": [
    "## Delete old standings file and scrape new with most recent scores\n",
    "os.remove('data/standings/NBA_2023_games-january.html')  ##Update month as needed\n",
    "await scrape_season(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f6ab519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clippers vs Mavericks, January 22, 2023 | Basketball-Reference.com\n",
      "Pelicans vs Heat, January 22, 2023 | Basketball-Reference.com\n",
      "Knicks vs Raptors, January 22, 2023 | Basketball-Reference.com\n",
      "Thunder vs Nuggets, January 22, 2023 | Basketball-Reference.com\n",
      "Timeout error on https://www.basketball-reference.com/boxscores/202301220PHO.html\n",
      "Grizzlies vs Suns, January 22, 2023 | Basketball-Reference.com\n",
      "Nets vs Warriors, January 22, 2023 | Basketball-Reference.com\n",
      "Lakers vs Trail Blazers, January 22, 2023 | Basketball-Reference.com\n",
      "Bucks vs Pistons, January 23, 2023 | Basketball-Reference.com\n",
      "Celtics vs Magic, January 23, 2023 | Basketball-Reference.com\n",
      "Hawks vs Bulls, January 23, 2023 | Basketball-Reference.com\n",
      "Timberwolves vs Rockets, January 23, 2023 | Basketball-Reference.com\n",
      "Hornets vs Jazz, January 23, 2023 | Basketball-Reference.com\n",
      "Timeout error on https://www.basketball-reference.com/boxscores/202301230POR.html\n",
      "Spurs vs Trail Blazers, January 23, 2023 | Basketball-Reference.com\n",
      "Grizzlies vs Kings, January 23, 2023 | Basketball-Reference.com\n"
     ]
    }
   ],
   "source": [
    "## run scrape_game function which opens each box score and saves it as an html file - skips if file already exists\n",
    "for season in SEASONS:\n",
    "    files = [s for s in standings_files if str(season) in s]\n",
    "    \n",
    "    for f in files:\n",
    "        filepath = os.path.join(STANDINGS_DIR, f)\n",
    "        \n",
    "        await scrape_game(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f95593",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_scores = os.listdir(TEMP_DIR)\n",
    "box_scores = [os.path.join(TEMP_DIR, f) for f in box_scores if f.endswith(\".html\")]\n",
    "games = []\n",
    "base_cols = None\n",
    "for box_score in box_scores:\n",
    "    soup = parse_html(box_score)\n",
    "\n",
    "    line_score = read_line_score_test(soup)\n",
    "    teams = list(line_score[\"team\"])\n",
    "\n",
    "    summaries = []\n",
    "    for team in teams:\n",
    "        basic = read_stats(soup, team, \"basic\")\n",
    "        advanced = read_stats(soup, team, \"advanced\")\n",
    "\n",
    "        totals = pd.concat([basic.iloc[-1,:], advanced.iloc[-1,:]])\n",
    "        totals.index = totals.index.str.lower()\n",
    "\n",
    "        maxes = pd.concat([basic.iloc[:-1].max(), advanced.iloc[:-1].max()])\n",
    "        maxes.index = maxes.index.str.lower() + \"_max\"\n",
    "\n",
    "        summary = pd.concat([totals, maxes])\n",
    "        \n",
    "        if base_cols is None:\n",
    "            base_cols = list(summary.index.drop_duplicates(keep=\"first\"))\n",
    "            base_cols = [b for b in base_cols if \"bpm\" not in b]\n",
    "        \n",
    "        summary = summary[base_cols]\n",
    "        \n",
    "        summaries.append(summary)\n",
    "    summary = pd.concat(summaries, axis=1).T\n",
    "\n",
    "    game = pd.concat([summary, line_score], axis=1)\n",
    "\n",
    "    game[\"home\"] = [0,1]\n",
    "\n",
    "    game_opp = game.iloc[::-1].reset_index()\n",
    "    game_opp.columns += \"_opp\"\n",
    "\n",
    "    full_game = pd.concat([game, game_opp], axis=1)\n",
    "    full_game[\"season\"] = read_season_info(soup)\n",
    "    \n",
    "    full_game[\"date\"] = os.path.basename(box_score)[:8]\n",
    "    full_game[\"date\"] = pd.to_datetime(full_game[\"date\"], format=\"%Y%m%d\")\n",
    "    \n",
    "    full_game[\"won\"] = full_game[\"total\"] > full_game[\"total_opp\"]\n",
    "    games.append(full_game)\n",
    "    \n",
    "    if len(games) % 100 == 0:\n",
    "        print(f\"{len(games)} / {len(box_scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e3c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = pd.read_csv(\"nba_games_updated.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3324ab3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp</th>\n",
       "      <th>mp.1</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg%</th>\n",
       "      <th>3p</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3p%</th>\n",
       "      <th>ft</th>\n",
       "      <th>fta</th>\n",
       "      <th>...</th>\n",
       "      <th>tov%_max_opp</th>\n",
       "      <th>usg%_max_opp</th>\n",
       "      <th>ortg_max_opp</th>\n",
       "      <th>drtg_max_opp</th>\n",
       "      <th>team_opp</th>\n",
       "      <th>total_opp</th>\n",
       "      <th>home_opp</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.528</td>\n",
       "      <td>16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.432</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.2</td>\n",
       "      <td>26.8</td>\n",
       "      <td>155.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.476</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.359</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.3</td>\n",
       "      <td>160.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>POR</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.526</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.6</td>\n",
       "      <td>41.1</td>\n",
       "      <td>250.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.392</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.342</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.6</td>\n",
       "      <td>33.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.300</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mp   mp.1    fg   fga    fg%    3p   3pa    3p%    ft   fta  ...  \\\n",
       "0  240.0  240.0  38.0  72.0  0.528  16.0  37.0  0.432  18.0  21.0  ...   \n",
       "1  240.0  240.0  40.0  84.0  0.476  14.0  39.0  0.359  13.0  15.0  ...   \n",
       "2  240.0  240.0  41.0  78.0  0.526   8.0  24.0  0.333  15.0  19.0  ...   \n",
       "3  240.0  240.0  29.0  74.0  0.392  13.0  38.0  0.342  19.0  26.0  ...   \n",
       "4  240.0  240.0  39.0  81.0  0.481   6.0  20.0  0.300  14.0  18.0  ...   \n",
       "\n",
       "   tov%_max_opp  usg%_max_opp  ortg_max_opp  drtg_max_opp  team_opp  \\\n",
       "0          26.2          26.8         155.0         123.0       MIA   \n",
       "1          41.0          37.3         160.0         121.0       POR   \n",
       "2          28.6          41.1         250.0         125.0       DAL   \n",
       "3          12.6          33.0         183.0         110.0       CLE   \n",
       "4          22.8          29.0         178.0         111.0       DAL   \n",
       "\n",
       "   total_opp  home_opp  season        date    won  \n",
       "0        107         1    2023  2022-11-07   True  \n",
       "1        110         0    2023  2022-11-07  False  \n",
       "2         90         1    2023  2022-12-14   True  \n",
       "3        105         0    2023  2022-12-14  False  \n",
       "4         95         1    2016  2015-12-09   True  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4434037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.concat(games, ignore_index=True)\n",
    "temp_df.to_csv(\"temp.csv\")\n",
    "temp = pd.read_csv(\"temp.csv\",index_col=0)\n",
    "old = pd.read_csv(\"nba_games_updated.csv\",index_col=0)\n",
    "save = pd.concat([old,temp])\n",
    "save.team = save.team.str.replace('CHO','CHA').str.replace('PHO','PHX').str.replace('BRK','BKN').str.replace('NJN','BKN').str.replace('NOH','NOP')\n",
    "save.to_csv(\"nba_games_updated.csv\")\n",
    "\n",
    "# gather all files\n",
    "allfiles = os.listdir(TEMP_DIR)\n",
    " \n",
    "# iterate on all files to move them to destination folder\n",
    "for f in allfiles:\n",
    "    src_path = os.path.join(TEMP_DIR, f)\n",
    "    dst_path = os.path.join(SCORES_DIR, f)\n",
    "    os.rename(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2965aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mp</th>\n",
       "      <th>mp.1</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg%</th>\n",
       "      <th>3p</th>\n",
       "      <th>3pa</th>\n",
       "      <th>3p%</th>\n",
       "      <th>ft</th>\n",
       "      <th>fta</th>\n",
       "      <th>...</th>\n",
       "      <th>tov%_max_opp</th>\n",
       "      <th>usg%_max_opp</th>\n",
       "      <th>ortg_max_opp</th>\n",
       "      <th>drtg_max_opp</th>\n",
       "      <th>team_opp</th>\n",
       "      <th>total_opp</th>\n",
       "      <th>home_opp</th>\n",
       "      <th>season</th>\n",
       "      <th>date</th>\n",
       "      <th>won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.407</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>34.2</td>\n",
       "      <td>155.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>30.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.2</td>\n",
       "      <td>37.4</td>\n",
       "      <td>277.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.438</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.371</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.6</td>\n",
       "      <td>28.3</td>\n",
       "      <td>157.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>LAC</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-22</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.7</td>\n",
       "      <td>29.6</td>\n",
       "      <td>228.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>UTA</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.477</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.3</td>\n",
       "      <td>31.3</td>\n",
       "      <td>200.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>CHO</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mp   mp.1    fg   fga    fg%    3p   3pa    3p%    ft   fta  ...  \\\n",
       "23  240.0  240.0  43.0  84.0  0.512  11.0  27.0  0.407  16.0  24.0  ...   \n",
       "24  240.0  240.0  35.0  77.0  0.455  12.0  28.0  0.429  30.0  31.0  ...   \n",
       "25  240.0  240.0  35.0  80.0  0.438  13.0  35.0  0.371  15.0  26.0  ...   \n",
       "26  240.0  240.0  38.0  85.0  0.447   2.0  16.0  0.125  24.0  34.0  ...   \n",
       "27  240.0  240.0  41.0  86.0  0.477  16.0  40.0  0.400  22.0  26.0  ...   \n",
       "\n",
       "    tov%_max_opp  usg%_max_opp  ortg_max_opp  drtg_max_opp  team_opp  \\\n",
       "23         100.0          34.2         155.0         126.0       BOS   \n",
       "24          20.2          37.4         277.0         134.0       DAL   \n",
       "25          25.6          28.3         157.0         117.0       LAC   \n",
       "26          66.7          29.6         228.0         109.0       UTA   \n",
       "27          31.3          31.3         200.0         125.0       CHO   \n",
       "\n",
       "    total_opp  home_opp  season        date    won  \n",
       "23         98         0    2023  2023-01-23   True  \n",
       "24         98         1    2023  2023-01-22   True  \n",
       "25        112         0    2023  2023-01-22  False  \n",
       "26        120         1    2023  2023-01-23  False  \n",
       "27        102         0    2023  2023-01-23   True  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209d37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
